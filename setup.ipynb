{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyGS.datastruct.scalefree import scalefree\n",
    "from pyGS.datastruct.Dataset import Dataset\n",
    "from pyGS.datastruct.randomNet import randomNet\n",
    "from pyGS.datastruct.stabilize import stabilize\n",
    "from pyGS.datastruct.Network import Network\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/mambaforge/base/envs/pyGS/lib/python3.12/site-packages/cvxpy/reductions/solvers/solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Ne = Network()\n",
    "import numpy as np\n",
    "# Defining number of nodes\n",
    "N = 10\n",
    "# Defining the sparsity\n",
    "S = 0.25\n",
    "A = randomNet(N,S)-np.eye(N)\n",
    "A = stabilize(A,'iaa','high')\n",
    "Net = Ne.Network(A,'random')\n",
    "# creator_setting = {'creator':'Nordlinglab_Justin'}\n",
    "# Net.setname(Net,creator_setting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyGS.datastruct.Network.Network at 0x31a84cbc0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "N = int(50)\n",
    "S = int(3)\n",
    "import pyGS.datastruct as datastruct\n",
    "from pyGS.datastruct.scalefree2 import scalefree2\n",
    "from pyGS.datastruct.scalefree import scalefree\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "A = scalefree2(N, S)\n",
    "A = stabilize(A,'iaa','low')\n",
    "Net = Network(A, 'myNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume Net.G is the static gain matrix and Net.network is the network adjacency matrix\n",
    "# For this example, we create a dummy network and a gain matrix\n",
    "N = 100  # Number of nodes\n",
    "Net_G = np.random.normal(size=(N, 2*N))  # Static gain model\n",
    "Net_network = np.random.rand(N, N) > 0.95  # Sparse network\n",
    "\n",
    "# Create P matrix\n",
    "P = -np.hstack([np.eye(N), np.eye(N)])\n",
    "\n",
    "# Create data\n",
    "X = np.dot(Net_G, P)  # Matrix multiplication\n",
    "\n",
    "# Add noise to data\n",
    "# Define signal-to-noise ratio\n",
    "SNR = 0.1  # usually 1 is low, 0.1 is medium, 0.01 is high noise\n",
    "s = svd(X, compute_uv=False)\n",
    "stdE = s[-1] / (SNR * np.sqrt(chi2.ppf(0.99, df=np.prod(P.shape))))  # Using 99% confidence\n",
    "\n",
    "# Estimate noise matrix\n",
    "E = stdE * np.random.randn(*P.shape)\n",
    "\n",
    "# Input noise matrix\n",
    "F = np.zeros_like(P)\n",
    "\n",
    "# Prepare data structure object\n",
    "D = {\n",
    "    'network': Net_network,\n",
    "    'E': E,\n",
    "    'F': F,\n",
    "    'Y': X + E,  # noise-free gene expression + noise\n",
    "    'P': P,\n",
    "    'lambda': [stdE**2, 0],\n",
    "    'cvY': stdE**2 * np.eye(N),\n",
    "    'cvP': np.zeros((N, N)),\n",
    "    'sdY': stdE * np.ones_like(P),\n",
    "    'sdP': np.zeros_like(P)\n",
    "}\n",
    "\n",
    "# Placeholder for creating data object with data \"D\" and scale-free network \"Net\"\n",
    "# Assuming we need to write a class or function `Dataset` and `Methods.lsco` to handle this\n",
    "# This part is highly context-specific and would require implementing or using existing library functions\n",
    "\n",
    "# Example placeholder functions and classes (implement these according to your actual needs)\n",
    "class Dataset:\n",
    "    def __init__(self, data, net):\n",
    "        self.data = data\n",
    "        self.net = net\n",
    "\n",
    "    # Placeholder for a method that runs inference\n",
    "    def run_inference(self, method, zeta):\n",
    "        # Example inference code (simplified)\n",
    "        return np.linalg.pinv(self.data['P']) @ self.data['Y'], zeta\n",
    "\n",
    "# Initialize Dataset\n",
    "data = Dataset(D, Net_network)\n",
    "\n",
    "# Now we can run inference and benchmark it against our gold standard\n",
    "zeta = np.logspace(-6, 0, 30)  # return 30 networks of full sparsity spectrum\n",
    "inf_method = 'lsco'\n",
    "Aest0, z0 = data.run_inference(inf_method, zeta)\n",
    "Aest01 = Aest0[:, :, 25]  # Select network 25\n",
    "\n",
    "# Display AUROC and max F1 score - placeholders for actual implementation\n",
    "print(\"AUROC: Placeholder value\")\n",
    "print(\"Max F1 score: Placeholder value\")\n",
    "\n",
    "# The above Python code requires actual implementation of the Methods and analyse classes/methods.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyGS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
